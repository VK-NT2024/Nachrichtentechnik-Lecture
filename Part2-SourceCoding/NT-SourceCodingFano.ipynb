{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shannon-Fano-Codierung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Codierung nach Shannon-Fano ist ein verlustloser Kompressionsalgorithmus. Sie gliedert die Symbole sukzessive in Teilmengen auf, bis jede Teilmenge nur noch ein Symbol enthält und eine eindeutige Bitfolge zugeordnet werden kann. Die Elemente werden zunächst entsprechend ihrer Auftrittswahrscheinlichkeiten sortiert. Sie werden dann in zwei Teilmengen aufgeteilt, so dass beide Teilmengen ungefähr die gleiche Auftrittswahrscheinlichkeit besitzen. Der oberen Teilmenge wird beispielsweise das Bit 0, der unteren das Bit 1 zugeordnet. Beide Teilmengen werden dann nach dem gleichen Prinzip weiter unterteilt, bis jedes Element eine eindeutige Bitfolge erhalten hat. Es entsteht wie bei der Huffman-Codierung ein binärer Baum, an dessen Verzweigungen die Bit 0 bzw. 1 zugeordnet werden. \n",
    "\n",
    "Die Shannon-Fano-Codierung generiert einen präfixfreien Code und ist damit verlustlos. Sie liefert nicht zwingend die bestmögliche Kompression, ist also suboptimal. Allerdings stimmen die Ergebnisse von Huffman- und Shannon-Fano-Codierung häufig überein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python-Code zur Shannon-Fano-Codierung\n",
    "# code adapted from https://rosettacode.org/wiki/Huffman_coding#Python\n",
    "\n",
    "from operator import itemgetter\n",
    "import numpy as np\n",
    "\n",
    "Shannon_Fano_dict={}\n",
    "\n",
    "def Shannon_Fano_coding(seq, code):\n",
    "    a = {}\n",
    "    b = {}\n",
    "    if len(seq) == 1:\n",
    "        Shannon_Fano_dict[seq.popitem()[0]] = code\n",
    "        return 0\n",
    " \n",
    "    prob_cum = 0\n",
    "    prob_sum = sum(seq.values())\n",
    "    for i in sorted(seq.items(), key=itemgetter(1), reverse=False):\n",
    "        prob_cum += i[1]\n",
    "        if prob_cum < prob_sum/2:\n",
    "            a[i[0]] = seq[i[0]]\n",
    "        elif (prob_sum-sum(a.values())) > (sum(a.values())+i[1]):\n",
    "            a[i[0]] = seq[i[0]]\n",
    "        else:\n",
    "            b[i[0]] = seq[i[0]]\n",
    "    Shannon_Fano_coding(a, code + \"0\")\n",
    "    Shannon_Fano_coding(b, code + \"1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im folgenden Abschnitt wird der zu komprimierende Text definiert und statistisch analysiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folgender Text bestehend aus 573 Zeichen soll nun komprimiert werden.\n",
      "\n",
      " Auch hier lohnt es sich wieder, auf den Unterschied zwischen den untersuchten Textsorten hinzuweisen, da sich die Hamburger Gruppe nicht allein auf wissenschaftliche Informationstexte beschränkt. Trotzdem sei an dieser Stelle festgehalten, dass informationsdichtere Texte, also Texte mit einer höheren semantischen Redundanz, wie sie der theoretisch-deduktive Ansatz empfiehlt, für gewöhnlich einen behaltensfördernden Effekt erzeugen und sich entsprechend positiv auf die Verständlichkeit eines Textes auswirken – aber auch die Lesezeit unter Umständen wesentlich erhöhen. \n",
      "\n",
      "\n",
      "Der Text enthält 42 verschiedene Symbole.\n",
      "\n",
      "Die Entropie des Alphabetes ist 4.34 bit, die des Textes 2485.36 bit.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#zu komprimierender Text \n",
    "text = \"Auch hier lohnt es sich wieder, auf den Unterschied zwischen den untersuchten Textsorten hinzuweisen, da sich die Hamburger Gruppe nicht allein auf wissenschaftliche Informationstexte beschränkt. Trotzdem sei an dieser Stelle festgehalten, dass informationsdichtere Texte, also Texte mit einer höheren semantischen Redundanz, wie sie der theoretisch-deduktive Ansatz empfiehlt, für gewöhnlich einen behaltensfördernden Effekt erzeugen und sich entsprechend positiv auf die Verständlichkeit eines Textes auswirken – aber auch die Lesezeit unter Umständen wesentlich erhöhen.\"\n",
    "text_length_symbols = len(text)\n",
    "\n",
    "print (\"Folgender Text bestehend aus %g Zeichen soll nun komprimiert werden.\\n\\n %s \\n\" % (text_length_symbols,text))\n",
    "\n",
    "# Generiere Liste mit Symbolen (Buchstaben) und ihren Auftrittswahrscheinlichkeiten\n",
    "symbol_count = {}\n",
    "for ch in text:\n",
    "    if ch not in symbol_count:\n",
    "        symbol_count[ch] = 1\n",
    "    else:\n",
    "        symbol_count[ch] += 1\n",
    "\n",
    "# symbol_count = {\"A\": 25, \"B\": 23, \"C\": 22, \"D\": 10, \"E\": 8, \"F\": 7, \"G\": 5}\n",
    "\n",
    "\n",
    "# Anzahl unterschiedlicher Zeichen in text\n",
    "symbol_number = len(symbol_count)\n",
    "print(\"\\nDer Text enthält %g verschiedene Symbole.\\n\" % (symbol_number))\n",
    "\n",
    "# Bestimme Auftrittswahrscheinlichkeit der einzelnen Symbole\n",
    "prob = np.zeros(len(symbol_count))\n",
    "cntr = 0\n",
    "for sym, freq in symbol_count.items():\n",
    "    prob[cntr] = freq / text_length_symbols\n",
    "    cntr +=1\n",
    "\n",
    "\n",
    "\n",
    "# Berechne Entropie des Textes\n",
    "entropy = - np.inner(prob, np.log2(prob))\n",
    "\n",
    "print(\"Die Entropie des Alphabetes ist %1.2f bit, die des Textes %1.2f bit.\\n\" % (entropy, entropy*text_length_symbols) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bei einer einfachen binären Codierung ohne Berücksichtigung der Auftrittswahrscheinlichkeiten müssten 6 bit pro Zeichen aufgewendet werden.\n",
      "\n",
      "Der codierte Text hätte eine Länge von 3438 bit.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# einfache binäre Codierung ohne Berücksichtigung der Auftrittswahrscheinlichkeiten\n",
    "equal_symbol_length_bit = np.ceil(np.log2(symbol_number))\n",
    "equal_text_length_bit = equal_symbol_length_bit * text_length_symbols\n",
    "\n",
    "print(\"Bei einer einfachen binären Codierung ohne Berücksichtigung der Auftrittswahrscheinlichkeiten müssten %g bit pro Zeichen aufgewendet werden.\\n\" % (equal_symbol_length_bit))\n",
    "print(\"Der codierte Text hätte eine Länge von %g bit.\\n\" %(equal_text_length_bit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit dem obigen Python-Code kann nun die Shannon-Fano-Codierung durchgeführt werden. Die binären Codeworte sind von links nach rechts zu lesen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symbol\tGewicht\tShannon-Fano-Code\n",
      "e\t88\t111\n",
      " \t71\t110\n",
      "n\t45\t101\n",
      "i\t40\t1001\n",
      "t\t38\t1000\n",
      "s\t36\t0111\n",
      "h\t31\t0110\n",
      "r\t28\t0101\n",
      "d\t23\t01001\n",
      "a\t20\t01000\n",
      "c\t19\t00111\n",
      "u\t16\t00110\n",
      "l\t13\t001011\n",
      "f\t12\t001010\n",
      "o\t10\t001001\n",
      "w\t8\t000111\n",
      "m\t8\t001000\n",
      "z\t7\t0001101\n",
      ",\t6\t0001100\n",
      "x\t5\t000100\n",
      "p\t5\t0001010\n",
      "k\t5\t0001011\n",
      "T\t5\t0000111\n",
      "ö\t4\t0000110\n",
      "g\t4\t0000101\n",
      "b\t4\t00001001\n",
      "ä\t3\t00001000\n",
      "v\t2\t000001111\n",
      "U\t2\t00000110\n",
      "A\t2\t00000101\n",
      ".\t2\t000001110\n",
      "–\t1\t000001000\n",
      "ü\t1\t000000110\n",
      "V\t1\t0000001111\n",
      "S\t1\t000000011\n",
      "R\t1\t000000100\n",
      "L\t1\t000001001\n",
      "I\t1\t000000010\n",
      "H\t1\t000000000\n",
      "G\t1\t000000001\n",
      "E\t1\t0000001110\n",
      "-\t1\t000000101\n"
     ]
    }
   ],
   "source": [
    "# Rufe Routine für Shannon-Fano-Codierung auf\n",
    "Shannon_Fano_coding(symbol_count, \"\")   # dictionary\n",
    "\n",
    "# sortierte Liste des Dictionaries\n",
    "sorted_symbol_count = sorted(((value, key) for (key,value) in symbol_count.items()), reverse=True)\n",
    "\n",
    "#print(Shannon_Fano_dict.values())\n",
    "print(\"Symbol\\tGewicht\\tShannon-Fano-Code\")\n",
    "code_len = np.zeros(len(symbol_count))\n",
    "cntr = 0\n",
    "for p in sorted_symbol_count:\n",
    "    print(\"%s\\t%s\\t%s\" % (p[1], p[0], Shannon_Fano_dict[p[1]]))\n",
    "    code_len[cntr] = len(Shannon_Fano_dict[p[1]])\n",
    "    cntr +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die mittlere Wortlänge des Shannon-Fano-Codes beträgt 4.96 bit pro Symbol.\n",
      "\n",
      "Die Länge des codierten Textes ist 2843 Bit.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Berechnung der Entropie des Textes (Annahme: Text ist repräsentativ.)\n",
    "fano_symbol_length_bit = np.inner(prob,code_len)\n",
    "fano_text_length_bit = fano_symbol_length_bit*text_length_symbols\n",
    "print(\"Die mittlere Wortlänge des Shannon-Fano-Codes beträgt %1.2f bit pro Symbol.\\n\" % (fano_symbol_length_bit))\n",
    "print(\"Die Länge des codierten Textes ist %g Bit.\\n\" % (fano_text_length_bit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die Redundanz des Shannon-Fano-Codes beträgt für dieses Beispiel 0.62 bit oder 12.58%.\n",
      "\n",
      "Verglichen mit der Codierung ohne Kompression konnte die Datenmenge um den Faktor 1.21 reduziert werden.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Bestimmung der Redundanz des Shannon-Fano-Codes\n",
    "redundancy = fano_symbol_length_bit - entropy\n",
    "print(\"Die Redundanz des Shannon-Fano-Codes beträgt für dieses Beispiel %1.2f bit oder %1.2f%%.\\n\" % (redundancy,redundancy/fano_symbol_length_bit*100))\n",
    "print(\"Verglichen mit der Codierung ohne Kompression konnte die Datenmenge um den Faktor %1.2f reduziert werden.\\n\" %(equal_text_length_bit/fano_text_length_bit))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
