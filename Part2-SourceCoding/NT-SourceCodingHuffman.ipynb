{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Huffman-Codierung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Huffman-Codierung ist das optimale verlustfreie Kompressionsverfahren. Es sortiert die Elemente zunächst entsprechend ihrer Auftrittswahrscheinlichkeiten. Dann werden rekursiv die beiden Elemente mit den kleinsten Auftrittswahrscheinlichkeiten zu einem neuen Element zusammengefasst, bis nur noch ein Element übrig bleibt. Es entsteht so ein binärer Baum, an dessen Verzweigungen die Bit 0 bzw. 1 zugeordnet werden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python-Code zur Huffman-Codierung\n",
    "# code taken from https://rosettacode.org/wiki/Huffman_coding#Python\n",
    "\n",
    "from heapq import heappush, heappop, heapify\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "def encode(symb2freq):\n",
    "    \"\"\"Huffman encode the given dict mapping symbols to weights\"\"\"\n",
    "    heap = [[wt, [sym, \"\"]] for sym, wt in symb2freq.items()]\n",
    "    heapify(heap)\n",
    "    while len(heap) > 1:\n",
    "        lo = heappop(heap)\n",
    "        hi = heappop(heap)\n",
    "        for pair in lo[1:]:\n",
    "            pair[1] = '0' + pair[1]\n",
    "        for pair in hi[1:]:\n",
    "            pair[1] = '1' + pair[1]\n",
    "        heappush(heap, [lo[0] + hi[0]] + lo[1:] + hi[1:])\n",
    "    return sorted(heappop(heap)[1:], key=lambda p: (len(p[-1]), p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im folgenden Abschnitt wird der zu komprimierende Text \n",
    "\n",
    "\"Auch hier lohnt es sich wieder, auf den Unterschied zwischen den untersuchten Textsorten hinzuweisen, da sich die Hamburger Gruppe nicht allein auf wissenschaftliche Informationstexte beschränkt. Trotzdem sei an dieser Stelle festgehalten, dass informationsdichtere Texte, also Texte mit einer höheren semantischen Redundanz, wie sie der theoretisch-deduktive Ansatz empfiehlt, für gewöhnlich einen behaltensfördernden Effekt erzeugen und sich entsprechend positiv auf die Verständlichkeit eines Textes auswirken – aber auch die Lesezeit unter Umständen wesentlich erhöhen.\"\n",
    "\n",
    "definiert und statistisch analysiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Der Text bestehend aus 573 Zeichen soll nun komprimiert werden.\n",
      "\n",
      "Der Text enthält 42 verschiedene Symbole.\n",
      "\n",
      "Die Entropie des Alphabetes ist 4.33746 bit, die des Textes 2485.36 bit.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#zu komprimierender Text \n",
    "text = \"Auch hier lohnt es sich wieder, auf den Unterschied zwischen den untersuchten Textsorten hinzuweisen, da sich die Hamburger Gruppe nicht allein auf wissenschaftliche Informationstexte beschränkt. Trotzdem sei an dieser Stelle festgehalten, dass informationsdichtere Texte, also Texte mit einer höheren semantischen Redundanz, wie sie der theoretisch-deduktive Ansatz empfiehlt, für gewöhnlich einen behaltensfördernden Effekt erzeugen und sich entsprechend positiv auf die Verständlichkeit eines Textes auswirken – aber auch die Lesezeit unter Umständen wesentlich erhöhen.\"\n",
    "text_length_symbols = len(text)\n",
    "\n",
    "print (\"Der Text bestehend aus %g Zeichen soll nun komprimiert werden.\" % (text_length_symbols))\n",
    "\n",
    "# Generiere Liste mit Symbolen (Buchstaben) und ihren Auftrittswahrscheinlichkeiten\n",
    "symbol_count = defaultdict(int)\n",
    "for ch in text:\n",
    "    symbol_count[ch] += 1\n",
    "\n",
    "# Anzahl unterschiedlicher Zeichen in text\n",
    "symbol_number = len(symbol_count)\n",
    "print(\"\\nDer Text enthält %g verschiedene Symbole.\\n\" % (symbol_number))\n",
    "\n",
    "# Bestimme Auftrittswahrscheinlichkeit der einzelnen Symbole\n",
    "prob = np.zeros(len(symbol_count))\n",
    "cntr = 0\n",
    "for sym, freq in symbol_count.items():\n",
    "    prob[cntr] = freq / text_length_symbols\n",
    "    cntr +=1\n",
    "\n",
    "\n",
    "# Berechne Entropie des Textes\n",
    "entropy = - np.inner(prob, np.log2(prob))\n",
    "\n",
    "print(\"Die Entropie des Alphabetes ist %g bit, die des Textes %g bit.\\n\" % (entropy, entropy*text_length_symbols) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bei einer einfachen binären Codierung ohne Berücksichtigung der Auftrittswahrscheinlichkeiten müssten 6 bit pro Zeichen aufgewendet werden.\n",
      "\n",
      "Der codierte Text hätte eine Länge von 3438 bit.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# einfache binäre Codierung ohne Berücksichtigung der Auftrittswahrscheinlichkeiten\n",
    "equal_symbol_length_bit = np.ceil(np.log2(symbol_number))\n",
    "equal_text_length_bit = equal_symbol_length_bit * text_length_symbols\n",
    "\n",
    "print(\"Bei einer einfachen binären Codierung ohne Berücksichtigung der Auftrittswahrscheinlichkeiten müssten %g bit pro Zeichen aufgewendet werden.\\n\" % (equal_symbol_length_bit))\n",
    "print(\"Der codierte Text hätte eine Länge von %g bit.\\n\" %(equal_text_length_bit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit dem obigen Python-Code kann nun die Huffman-Codierung durchgeführt werden. Die binären Codeworte sind von links nach rechts zu lesen (im Beispiel der Vorlesung von rechts nach links)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symbol\tGewicht\tHuffman Code\n",
      " \t71\t011\n",
      "e\t88\t110\n",
      "h\t31\t0011\n",
      "i\t40\t1011\n",
      "n\t45\t1111\n",
      "r\t28\t0010\n",
      "s\t36\t1000\n",
      "t\t38\t1001\n",
      "a\t20\t10101\n",
      "c\t19\t10100\n",
      "d\t23\t11101\n",
      "f\t12\t00001\n",
      "l\t13\t00010\n",
      "u\t16\t01010\n",
      ",\t6\t000001\n",
      "m\t8\t010011\n",
      "o\t10\t111001\n",
      "w\t8\t010110\n",
      "x\t5\t000000\n",
      "z\t7\t000111\n",
      "T\t5\t0101111\n",
      "b\t4\t0100100\n",
      "g\t4\t0100101\n",
      "k\t5\t1110000\n",
      "p\t5\t1110001\n",
      "ä\t3\t0001100\n",
      "ö\t4\t0101110\n",
      ".\t2\t01000000\n",
      "A\t2\t01000001\n",
      "U\t2\t01000101\n",
      "v\t2\t01000111\n",
      "–\t1\t00011010\n",
      "-\t1\t000110110\n",
      "E\t1\t000110111\n",
      "G\t1\t010000100\n",
      "H\t1\t010000101\n",
      "I\t1\t010000110\n",
      "L\t1\t010000111\n",
      "R\t1\t010001000\n",
      "S\t1\t010001001\n",
      "V\t1\t010001100\n",
      "ü\t1\t010001101\n"
     ]
    }
   ],
   "source": [
    "# Rufe Routine für Huffman-Codierung auf\n",
    "huff = encode(symbol_count)\n",
    "\n",
    "# Drucke Ergebnis\n",
    "print(\"Symbol\\tGewicht\\tHuffman Code\")\n",
    "code_len = np.zeros(len(symbol_count))\n",
    "cntr = 0\n",
    "for p in huff:\n",
    "    print(\"%s\\t%s\\t%s\" % (p[0], symbol_count[p[0]], p[1]))\n",
    "    code_len[cntr] = len(p[1])\n",
    "    cntr +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die mittlere Wortlänge des Huffman-Codes beträgt 4.85515 bit pro Symbol.\n",
      "\n",
      "Die Länge des codierten Textes ist 2782 Bit.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Berechnung der Entropie des Textes (Annahme: Text ist repräsentativ.)\n",
    "huff_symbol_length_bit = np.inner(prob,code_len)\n",
    "huff_text_length_bit = huff_symbol_length_bit*text_length_symbols\n",
    "print(\"Die mittlere Wortlänge des Huffman-Codes beträgt %g bit pro Symbol.\\n\" % (huff_symbol_length_bit))\n",
    "print(\"Die Länge des codierten Textes ist %g Bit.\\n\" % (huff_text_length_bit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die Redundanz des Huffman-Codes beträgt für dieses Beispiel 0.517692 bit oder 10.6627%.\n",
      "\n",
      "Verglichen mit der Codierung ohne Kompression konnte die Datenmenge um den Faktor 1.2358 reduziert werden.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Bestimmung der Redundanz des Huffman-Codes\n",
    "redundancy = huff_symbol_length_bit - entropy\n",
    "print(\"Die Redundanz des Huffman-Codes beträgt für dieses Beispiel %g bit oder %g%%.\\n\" % (redundancy,redundancy/huff_symbol_length_bit*100))\n",
    "print(\"Verglichen mit der Codierung ohne Kompression konnte die Datenmenge um den Faktor %g reduziert werden.\\n\" %(equal_text_length_bit/huff_text_length_bit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'A': 2,\n",
       "             'u': 16,\n",
       "             'c': 19,\n",
       "             'h': 31,\n",
       "             ' ': 71,\n",
       "             'i': 40,\n",
       "             'e': 88,\n",
       "             'r': 28,\n",
       "             'l': 13,\n",
       "             'o': 10,\n",
       "             'n': 45,\n",
       "             't': 38,\n",
       "             's': 36,\n",
       "             'w': 8,\n",
       "             'd': 23,\n",
       "             ',': 6,\n",
       "             'a': 20,\n",
       "             'f': 12,\n",
       "             'U': 2,\n",
       "             'z': 7,\n",
       "             'T': 5,\n",
       "             'x': 5,\n",
       "             'H': 1,\n",
       "             'm': 8,\n",
       "             'b': 4,\n",
       "             'g': 4,\n",
       "             'G': 1,\n",
       "             'p': 5,\n",
       "             'I': 1,\n",
       "             'ä': 3,\n",
       "             'k': 5,\n",
       "             '.': 2,\n",
       "             'S': 1,\n",
       "             'ö': 4,\n",
       "             'R': 1,\n",
       "             '-': 1,\n",
       "             'v': 2,\n",
       "             'ü': 1,\n",
       "             'E': 1,\n",
       "             'V': 1,\n",
       "             '–': 1,\n",
       "             'L': 1})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbol_count"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
